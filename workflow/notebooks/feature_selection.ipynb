{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bioframe as bf\n",
    "from datasets import load_dataset\n",
    "from gpn.data import Genome, load_table, load_dataset_from_file_or_dir\n",
    "from liftover import get_lifter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from scipy.spatial.distance import cdist\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, SelectFdr\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>pos</th>\n",
       "      <th>ref</th>\n",
       "      <th>alt</th>\n",
       "      <th>MAF</th>\n",
       "      <th>PIP</th>\n",
       "      <th>label</th>\n",
       "      <th>consequence</th>\n",
       "      <th>tss_dist</th>\n",
       "      <th>match_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1164939</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>0.062955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>dELS</td>\n",
       "      <td>8940</td>\n",
       "      <td>dELS_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1468048</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>0.070269</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>dELS</td>\n",
       "      <td>3716</td>\n",
       "      <td>dELS_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1471144</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>0.071226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>pELS</td>\n",
       "      <td>620</td>\n",
       "      <td>pELS_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6243564</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>0.071789</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>False</td>\n",
       "      <td>pELS</td>\n",
       "      <td>614</td>\n",
       "      <td>pELS_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6410895</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>0.062965</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>True</td>\n",
       "      <td>dELS</td>\n",
       "      <td>9007</td>\n",
       "      <td>dELS_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>22</td>\n",
       "      <td>39457735</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>0.245940</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>pELS</td>\n",
       "      <td>722</td>\n",
       "      <td>pELS_13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>22</td>\n",
       "      <td>42286551</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>0.250440</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>False</td>\n",
       "      <td>dELS</td>\n",
       "      <td>2553</td>\n",
       "      <td>dELS_80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>22</td>\n",
       "      <td>46683646</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>0.060253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>dELS</td>\n",
       "      <td>9037</td>\n",
       "      <td>dELS_75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>22</td>\n",
       "      <td>49957690</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>0.248880</td>\n",
       "      <td>0.999554</td>\n",
       "      <td>True</td>\n",
       "      <td>dELS</td>\n",
       "      <td>3081</td>\n",
       "      <td>dELS_80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>22</td>\n",
       "      <td>49960363</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>0.244700</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>False</td>\n",
       "      <td>pELS</td>\n",
       "      <td>408</td>\n",
       "      <td>pELS_13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>306 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    chrom       pos ref alt       MAF       PIP  label consequence  tss_dist  \\\n",
       "0       1   1164939   C   A  0.062955  0.000000  False        dELS      8940   \n",
       "1       1   1468048   A   G  0.070269  1.000000   True        dELS      3716   \n",
       "2       1   1471144   G   C  0.071226  1.000000   True        pELS       620   \n",
       "3       1   6243564   C   T  0.071789  0.001052  False        pELS       614   \n",
       "4       1   6410895   T   C  0.062965  0.999993   True        dELS      9007   \n",
       "..    ...       ...  ..  ..       ...       ...    ...         ...       ...   \n",
       "301    22  39457735   G   A  0.245940  1.000000   True        pELS       722   \n",
       "302    22  42286551   T   C  0.250440  0.000697  False        dELS      2553   \n",
       "303    22  46683646   A   G  0.060253  0.000000  False        dELS      9037   \n",
       "304    22  49957690   C   G  0.248880  0.999554   True        dELS      3081   \n",
       "305    22  49960363   G   A  0.244700  0.000644  False        pELS       408   \n",
       "\n",
       "    match_group  \n",
       "0        dELS_1  \n",
       "1        dELS_0  \n",
       "2        pELS_0  \n",
       "3        pELS_0  \n",
       "4        dELS_1  \n",
       "..          ...  \n",
       "301     pELS_13  \n",
       "302     dELS_80  \n",
       "303     dELS_75  \n",
       "304     dELS_80  \n",
       "305     pELS_13  \n",
       "\n",
       "[306 rows x 10 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset = \"Height\"\n",
    "dataset = \"IBD\"\n",
    "V = pd.read_parquet(f\"../../results/dataset/gwas_gokcen_{dataset}_cre_matched/test.parquet\")\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GC</th>\n",
       "      <th>CpG</th>\n",
       "      <th>motifECount</th>\n",
       "      <th>motifEHIPos</th>\n",
       "      <th>motifEScoreChng</th>\n",
       "      <th>minDistTSS</th>\n",
       "      <th>minDistTSE</th>\n",
       "      <th>priPhCons</th>\n",
       "      <th>mamPhCons</th>\n",
       "      <th>verPhCons</th>\n",
       "      <th>...</th>\n",
       "      <th>RegSeq4</th>\n",
       "      <th>RegSeq5</th>\n",
       "      <th>RegSeq6</th>\n",
       "      <th>RegSeq7</th>\n",
       "      <th>ZooPriPhyloP</th>\n",
       "      <th>ZooVerPhyloP</th>\n",
       "      <th>ZooRoCC</th>\n",
       "      <th>Roulette-MR</th>\n",
       "      <th>Roulette-AR</th>\n",
       "      <th>RawScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.728</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2166</td>\n",
       "      <td>2260</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002422</td>\n",
       "      <td>-0.012463</td>\n",
       "      <td>-0.006394</td>\n",
       "      <td>0.007449</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.339867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.662</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5565</td>\n",
       "      <td>616</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000089</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>-0.000210</td>\n",
       "      <td>0.003044</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-1.018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.226352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.517</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>622</td>\n",
       "      <td>981</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059325</td>\n",
       "      <td>0.005445</td>\n",
       "      <td>0.021399</td>\n",
       "      <td>0.008557</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-1.385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.070621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.636</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>616</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.058</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>-0.000423</td>\n",
       "      <td>0.002826</td>\n",
       "      <td>0.004220</td>\n",
       "      <td>0.320</td>\n",
       "      <td>5.909</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.128</td>\n",
       "      <td>2.463754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.517</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5737</td>\n",
       "      <td>1524</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>0.001680</td>\n",
       "      <td>-0.011233</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-1.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.017440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>0.821</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>723</td>\n",
       "      <td>34460</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.565</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007857</td>\n",
       "      <td>-0.022018</td>\n",
       "      <td>-0.005359</td>\n",
       "      <td>0.013065</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.877372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>0.404</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>31689</td>\n",
       "      <td>71704</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004903</td>\n",
       "      <td>-0.004016</td>\n",
       "      <td>-0.008280</td>\n",
       "      <td>-0.021105</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.678291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>0.278</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>54607</td>\n",
       "      <td>765</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009435</td>\n",
       "      <td>0.021430</td>\n",
       "      <td>0.037646</td>\n",
       "      <td>-0.049947</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.367680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>0.649</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3079</td>\n",
       "      <td>3957</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000284</td>\n",
       "      <td>0.002480</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.228360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>0.669</td>\n",
       "      <td>0.147</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>406</td>\n",
       "      <td>1284</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001327</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.478283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>306 rows Ã— 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        GC    CpG  motifECount  motifEHIPos  motifEScoreChng  minDistTSS  \\\n",
       "0    0.728  0.120          0.0          0.0            0.000        2166   \n",
       "1    0.662  0.067          0.0          0.0            0.000        5565   \n",
       "2    0.517  0.067          0.0          0.0            0.000         622   \n",
       "3    0.636  0.053          0.0          0.0            0.000         616   \n",
       "4    0.517  0.053          0.0          0.0            0.000        5737   \n",
       "..     ...    ...          ...          ...              ...         ...   \n",
       "301  0.821  0.267          0.0          0.0            0.000         723   \n",
       "302  0.404  0.027          0.0          0.0            0.000       31689   \n",
       "303  0.278  0.013          0.0          0.0            0.000       54607   \n",
       "304  0.649  0.000          0.0          0.0            0.000        3079   \n",
       "305  0.669  0.147          4.0          1.0           -0.093         406   \n",
       "\n",
       "     minDistTSE  priPhCons  mamPhCons  verPhCons  ...   RegSeq4   RegSeq5  \\\n",
       "0          2260      0.004      0.004      0.000  ... -0.002422 -0.012463   \n",
       "1           616      0.020      0.000      0.000  ... -0.000089  0.000030   \n",
       "2           981      0.015      0.015      0.015  ... -0.059325  0.005445   \n",
       "3          2015      0.058      1.000      1.000  ...  0.000625 -0.000423   \n",
       "4          1524      0.005      0.008      0.008  ...  0.000364  0.001244   \n",
       "..          ...        ...        ...        ...  ...       ...       ...   \n",
       "301       34460      0.100      0.919      0.565  ... -0.007857 -0.022018   \n",
       "302       71704      0.006      0.000      0.000  ... -0.004903 -0.004016   \n",
       "303         765      0.087      0.086      0.084  ...  0.009435  0.021430   \n",
       "304        3957      0.151      0.000      0.000  ... -0.000046  0.000003   \n",
       "305        1284      0.001      0.000      0.000  ... -0.001327  0.000624   \n",
       "\n",
       "      RegSeq6   RegSeq7  ZooPriPhyloP  ZooVerPhyloP  ZooRoCC  Roulette-MR  \\\n",
       "0   -0.006394  0.007449         0.005         0.254      0.0        0.030   \n",
       "1   -0.000210  0.003044         0.001        -1.018      0.0        0.083   \n",
       "2    0.021399  0.008557         0.008        -1.385      0.0        0.041   \n",
       "3    0.002826  0.004220         0.320         5.909     25.0        0.128   \n",
       "4    0.001680 -0.011233         0.005        -1.125      0.0        0.105   \n",
       "..        ...       ...           ...           ...      ...          ...   \n",
       "301 -0.005359  0.013065         0.012         0.828      0.0        0.117   \n",
       "302 -0.008280 -0.021105         0.027         0.731      0.0        0.051   \n",
       "303  0.037646 -0.049947         0.003         0.708      0.0        0.083   \n",
       "304 -0.000284  0.002480         0.016         0.480      0.0        0.041   \n",
       "305  0.001434  0.001473         0.001         0.924      0.0        0.151   \n",
       "\n",
       "     Roulette-AR  RawScore  \n",
       "0          0.105  0.339867  \n",
       "1          0.105 -0.226352  \n",
       "2          0.041  0.070621  \n",
       "3          0.128  2.463754  \n",
       "4          0.105 -0.017440  \n",
       "..           ...       ...  \n",
       "301        0.105  0.877372  \n",
       "302        0.105  0.678291  \n",
       "303        0.105  0.367680  \n",
       "304        0.105 -0.228360  \n",
       "305        0.151  0.478283  \n",
       "\n",
       "[306 rows x 102 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#features_path = \"GPN-MSA_InnerProducts\"\n",
    "features_path = \"CADD\"\n",
    "#features_path = \"Borzoi_L2\"\n",
    "features = pd.read_parquet(f\"../../results/dataset/gwas_gokcen_{dataset}_cre_matched/features/{features_path}.parquet\")\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nSelectFdr does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#model = SelectKBest(score_func=f_classif, k=10)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m SelectFdr(score_func\u001b[38;5;241m=\u001b[39mf_classif, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(features, V[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      4\u001b[0m model\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:498\u001b[0m, in \u001b[0;36m_BaseFilter.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;124;03m\"\"\"Run score function on (X, y) and get the appropriate features.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \n\u001b[1;32m    484\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;124;03m        Returns the instance itself.\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 498\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m    499\u001b[0m         X, y, accept_sparse\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m], multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    500\u001b[0m     )\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params(X, y)\n\u001b[1;32m    503\u001b[0m     score_func_ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore_func(X, y)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sklearn/base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    620\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 622\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m    623\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sklearn/utils/validation.py:1146\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1143\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1144\u001b[0m     )\n\u001b[0;32m-> 1146\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1147\u001b[0m     X,\n\u001b[1;32m   1148\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   1149\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[1;32m   1150\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1151\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[1;32m   1152\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m   1153\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[1;32m   1154\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[1;32m   1155\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[1;32m   1156\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[1;32m   1157\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[1;32m   1158\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m   1159\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1160\u001b[0m )\n\u001b[1;32m   1162\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1164\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sklearn/utils/validation.py:957\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    951\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    952\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    953\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    954\u001b[0m         )\n\u001b[1;32m    956\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 957\u001b[0m         _assert_all_finite(\n\u001b[1;32m    958\u001b[0m             array,\n\u001b[1;32m    959\u001b[0m             input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m    960\u001b[0m             estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m    961\u001b[0m             allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    962\u001b[0m         )\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    965\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sklearn/utils/validation.py:122\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m _assert_all_finite_element_wise(\n\u001b[1;32m    123\u001b[0m     X,\n\u001b[1;32m    124\u001b[0m     xp\u001b[38;5;241m=\u001b[39mxp,\n\u001b[1;32m    125\u001b[0m     allow_nan\u001b[38;5;241m=\u001b[39mallow_nan,\n\u001b[1;32m    126\u001b[0m     msg_dtype\u001b[38;5;241m=\u001b[39mmsg_dtype,\n\u001b[1;32m    127\u001b[0m     estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m    128\u001b[0m     input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m    129\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sklearn/utils/validation.py:171\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    170\u001b[0m     )\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nSelectFdr does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "#model = SelectKBest(score_func=f_classif, k=10)\n",
    "model = SelectFdr(score_func=f_classif, alpha=0.05)\n",
    "model.fit(features, V[\"label\"])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([688, 147, 263, 137, 108, 580, 343, 221, 526, 552])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(model.scores_)[::-1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(model.get_support())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/accounts/projects/yss/gbenegas/.local/lib/python3.11/site-packages/sklearn/impute/_base.py:558: UserWarning: Skipping features without any observed values: ['MMSp_acceptorIntron' 'MMSp_acceptor']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/accounts/projects/yss/gbenegas/.local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/accounts/projects/yss/gbenegas/.local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/accounts/projects/yss/gbenegas/.local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/accounts/projects/yss/gbenegas/.local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/accounts/projects/yss/gbenegas/.local/lib/python3.11/site-packages/sklearn/impute/_base.py:558: UserWarning: Skipping features without any observed values: ['MMSp_acceptorIntron' 'MMSp_acceptor']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5800303592511384"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = features\n",
    "y = V.label\n",
    "mask_train = V.chrom.isin([str(i) for i in range(1, 23, 2)] + [\"X\"])\n",
    "X_train = X[mask_train]\n",
    "y_train = y[mask_train]\n",
    "X_test = X[~mask_train]\n",
    "y_test = y[~mask_train]\n",
    "balanced = True\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('imputer', SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
    "    ('scaler', RobustScaler()),\n",
    "    #('feature_selection', SelectKBest(score_func=f_classif, k=30)),\n",
    "    #('feature_selection', SelectFdr(score_func=f_classif, alpha=0.05)),\n",
    "    #('feature_selection', SelectFromModel(LogisticRegression(C=1e-1, penalty=\"l1\", random_state=42, solver=\"saga\"))),\n",
    "    ('linear', LogisticRegressionCV(\n",
    "        class_weight=\"balanced\",\n",
    "        scoring=\"roc_auc\" if balanced else \"average_precision\",\n",
    "        Cs=np.logspace(-10, 10, 41),\n",
    "        cv=3,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    ))\n",
    "    #(\n",
    "    #    'random_forest',\n",
    "    #    RandomForestClassifier(\n",
    "    #        class_weight=\"balanced\",\n",
    "    #        n_estimators=1000,\n",
    "    #        random_state=42,\n",
    "    #        n_jobs=-1,\n",
    "    #    )\n",
    "    #),\n",
    "])\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict_proba(X_test)[:, 1]\n",
    "roc_auc_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpn",
   "language": "python",
   "name": "gpn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
